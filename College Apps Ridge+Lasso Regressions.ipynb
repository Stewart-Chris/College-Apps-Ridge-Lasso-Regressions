{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a7d873b81499092078909b42c23507dd",
     "grade": false,
     "grade_id": "cell-fcb5428619197f27",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Regression: Ridge & Lasso Regressions on College Applications\n",
    "\n",
    "We will use the College dataset to predict the number of applications ('Apps') received using the other variables in the College dataset. We will then use regularization to study their effects on our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Private</th>\n",
       "      <th>Apps</th>\n",
       "      <th>Accept</th>\n",
       "      <th>Enroll</th>\n",
       "      <th>Top10perc</th>\n",
       "      <th>Top25perc</th>\n",
       "      <th>F_Undergrad</th>\n",
       "      <th>P_Undergrad</th>\n",
       "      <th>Outstate</th>\n",
       "      <th>Room_Board</th>\n",
       "      <th>Books</th>\n",
       "      <th>Personal</th>\n",
       "      <th>PhD</th>\n",
       "      <th>Terminal</th>\n",
       "      <th>S_F_Ratio</th>\n",
       "      <th>perc_alumni</th>\n",
       "      <th>Expend</th>\n",
       "      <th>Grad_Rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Names</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abilene Christian University</th>\n",
       "      <td>1</td>\n",
       "      <td>1660</td>\n",
       "      <td>1232</td>\n",
       "      <td>721</td>\n",
       "      <td>23</td>\n",
       "      <td>52</td>\n",
       "      <td>2885</td>\n",
       "      <td>537</td>\n",
       "      <td>7440</td>\n",
       "      <td>3300</td>\n",
       "      <td>450</td>\n",
       "      <td>2200</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>18.1</td>\n",
       "      <td>12</td>\n",
       "      <td>7041</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adelphi University</th>\n",
       "      <td>1</td>\n",
       "      <td>2186</td>\n",
       "      <td>1924</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>2683</td>\n",
       "      <td>1227</td>\n",
       "      <td>12280</td>\n",
       "      <td>6450</td>\n",
       "      <td>750</td>\n",
       "      <td>1500</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>12.2</td>\n",
       "      <td>16</td>\n",
       "      <td>10527</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adrian College</th>\n",
       "      <td>1</td>\n",
       "      <td>1428</td>\n",
       "      <td>1097</td>\n",
       "      <td>336</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>1036</td>\n",
       "      <td>99</td>\n",
       "      <td>11250</td>\n",
       "      <td>3750</td>\n",
       "      <td>400</td>\n",
       "      <td>1165</td>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>12.9</td>\n",
       "      <td>30</td>\n",
       "      <td>8735</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agnes Scott College</th>\n",
       "      <td>1</td>\n",
       "      <td>417</td>\n",
       "      <td>349</td>\n",
       "      <td>137</td>\n",
       "      <td>60</td>\n",
       "      <td>89</td>\n",
       "      <td>510</td>\n",
       "      <td>63</td>\n",
       "      <td>12960</td>\n",
       "      <td>5450</td>\n",
       "      <td>450</td>\n",
       "      <td>875</td>\n",
       "      <td>92</td>\n",
       "      <td>97</td>\n",
       "      <td>7.7</td>\n",
       "      <td>37</td>\n",
       "      <td>19016</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alaska Pacific University</th>\n",
       "      <td>1</td>\n",
       "      <td>193</td>\n",
       "      <td>146</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>249</td>\n",
       "      <td>869</td>\n",
       "      <td>7560</td>\n",
       "      <td>4120</td>\n",
       "      <td>800</td>\n",
       "      <td>1500</td>\n",
       "      <td>76</td>\n",
       "      <td>72</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2</td>\n",
       "      <td>10922</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Private  Apps  Accept  Enroll  Top10perc  \\\n",
       "Names                                                                    \n",
       "Abilene Christian University        1  1660    1232     721         23   \n",
       "Adelphi University                  1  2186    1924     512         16   \n",
       "Adrian College                      1  1428    1097     336         22   \n",
       "Agnes Scott College                 1   417     349     137         60   \n",
       "Alaska Pacific University           1   193     146      55         16   \n",
       "\n",
       "                              Top25perc  F_Undergrad  P_Undergrad  Outstate  \\\n",
       "Names                                                                         \n",
       "Abilene Christian University         52         2885          537      7440   \n",
       "Adelphi University                   29         2683         1227     12280   \n",
       "Adrian College                       50         1036           99     11250   \n",
       "Agnes Scott College                  89          510           63     12960   \n",
       "Alaska Pacific University            44          249          869      7560   \n",
       "\n",
       "                              Room_Board  Books  Personal  PhD  Terminal  \\\n",
       "Names                                                                      \n",
       "Abilene Christian University        3300    450      2200   70        78   \n",
       "Adelphi University                  6450    750      1500   29        30   \n",
       "Adrian College                      3750    400      1165   53        66   \n",
       "Agnes Scott College                 5450    450       875   92        97   \n",
       "Alaska Pacific University           4120    800      1500   76        72   \n",
       "\n",
       "                              S_F_Ratio  perc_alumni  Expend  Grad_Rate  \n",
       "Names                                                                    \n",
       "Abilene Christian University       18.1           12    7041         60  \n",
       "Adelphi University                 12.2           16   10527         56  \n",
       "Adrian College                     12.9           30    8735         54  \n",
       "Agnes Scott College                 7.7           37   19016         59  \n",
       "Alaska Pacific University          11.9            2   10922         15  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load data, rename cols, then check head\n",
    "data = pd.read_csv('College.csv').copy()\n",
    "data.set_index('Names', inplace = True)\n",
    "data['Private'] = [1 if x==\"Yes\" else 0 for x in data['Private']]\n",
    "data = data.rename(columns = {'Grad.Rate':'Grad_Rate',\n",
    "                              'S.F.Ratio': 'S_F_Ratio',\n",
    "                              'perc.alumni':'perc_alumni',\n",
    "                              'Room.Board':'Room_Board',\n",
    "                              'F.Undergrad':'F_Undergrad',\n",
    "                              'P.Undergrad':'P_Undergrad'})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset into a training set and a test set\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0678ec0d5be7f0833b3a42d9c0899de7",
     "grade": false,
     "grade_id": "cell-88bb828acf7041d2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we'll fit a linear model using `Stats Models` on the training set where the target variable is `Apps`, and see the test MSE obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Apps</td>       <th>  R-squared:         </th> <td>   0.923</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.920</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   422.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 17 Oct 2023</td> <th>  Prob (F-statistic):</th> <td>1.77e-321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:37:29</td>     <th>  Log-Likelihood:    </th> <td> -5220.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   621</td>      <th>  AIC:               </th> <td>1.048e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   603</td>      <th>  BIC:               </th> <td>1.056e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    17</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>       <td> -680.7685</td> <td>  493.753</td> <td>   -1.379</td> <td> 0.168</td> <td>-1650.454</td> <td>  288.917</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Private</th>     <td> -355.4791</td> <td>  164.818</td> <td>   -2.157</td> <td> 0.031</td> <td> -679.166</td> <td>  -31.792</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Accept</th>      <td>    1.5759</td> <td>    0.046</td> <td>   34.022</td> <td> 0.000</td> <td>    1.485</td> <td>    1.667</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Enroll</th>      <td>   -0.7461</td> <td>    0.230</td> <td>   -3.246</td> <td> 0.001</td> <td>   -1.197</td> <td>   -0.295</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Top10perc</th>   <td>   50.2187</td> <td>    6.708</td> <td>    7.487</td> <td> 0.000</td> <td>   37.046</td> <td>   63.392</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Top25perc</th>   <td>  -14.9466</td> <td>    5.413</td> <td>   -2.761</td> <td> 0.006</td> <td>  -25.576</td> <td>   -4.317</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>F_Undergrad</th> <td>    0.0525</td> <td>    0.040</td> <td>    1.322</td> <td> 0.187</td> <td>   -0.025</td> <td>    0.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>P_Undergrad</th> <td>    0.0149</td> <td>    0.046</td> <td>    0.323</td> <td> 0.747</td> <td>   -0.076</td> <td>    0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Outstate</th>    <td>   -0.1016</td> <td>    0.023</td> <td>   -4.438</td> <td> 0.000</td> <td>   -0.147</td> <td>   -0.057</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Room_Board</th>  <td>    0.1818</td> <td>    0.059</td> <td>    3.081</td> <td> 0.002</td> <td>    0.066</td> <td>    0.298</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Books</th>       <td>   -0.0499</td> <td>    0.286</td> <td>   -0.174</td> <td> 0.862</td> <td>   -0.611</td> <td>    0.512</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Personal</th>    <td>    0.0208</td> <td>    0.076</td> <td>    0.274</td> <td> 0.784</td> <td>   -0.128</td> <td>    0.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PhD</th>         <td>   -8.8515</td> <td>    5.378</td> <td>   -1.646</td> <td> 0.100</td> <td>  -19.413</td> <td>    1.710</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Terminal</th>    <td>   -1.5801</td> <td>    5.936</td> <td>   -0.266</td> <td> 0.790</td> <td>  -13.238</td> <td>   10.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>S_F_Ratio</th>   <td>   18.2103</td> <td>   15.218</td> <td>    1.197</td> <td> 0.232</td> <td>  -11.676</td> <td>   48.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>perc_alumni</th> <td>   -0.1343</td> <td>    4.959</td> <td>   -0.027</td> <td> 0.978</td> <td>   -9.873</td> <td>    9.604</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Expend</th>      <td>    0.0822</td> <td>    0.014</td> <td>    5.820</td> <td> 0.000</td> <td>    0.054</td> <td>    0.110</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Grad_Rate</th>   <td>    9.0081</td> <td>    3.468</td> <td>    2.598</td> <td> 0.010</td> <td>    2.197</td> <td>   15.819</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>367.855</td> <th>  Durbin-Watson:     </th> <td>   2.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>6382.346</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.270</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>18.035</td>  <th>  Cond. No.          </th> <td>1.87e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.87e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   Apps   R-squared:                       0.923\n",
       "Model:                            OLS   Adj. R-squared:                  0.920\n",
       "Method:                 Least Squares   F-statistic:                     422.6\n",
       "Date:                Tue, 17 Oct 2023   Prob (F-statistic):          1.77e-321\n",
       "Time:                        14:37:29   Log-Likelihood:                -5220.3\n",
       "No. Observations:                 621   AIC:                         1.048e+04\n",
       "Df Residuals:                     603   BIC:                         1.056e+04\n",
       "Df Model:                          17                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "const        -680.7685    493.753     -1.379      0.168   -1650.454     288.917\n",
       "Private      -355.4791    164.818     -2.157      0.031    -679.166     -31.792\n",
       "Accept          1.5759      0.046     34.022      0.000       1.485       1.667\n",
       "Enroll         -0.7461      0.230     -3.246      0.001      -1.197      -0.295\n",
       "Top10perc      50.2187      6.708      7.487      0.000      37.046      63.392\n",
       "Top25perc     -14.9466      5.413     -2.761      0.006     -25.576      -4.317\n",
       "F_Undergrad     0.0525      0.040      1.322      0.187      -0.025       0.130\n",
       "P_Undergrad     0.0149      0.046      0.323      0.747      -0.076       0.106\n",
       "Outstate       -0.1016      0.023     -4.438      0.000      -0.147      -0.057\n",
       "Room_Board      0.1818      0.059      3.081      0.002       0.066       0.298\n",
       "Books          -0.0499      0.286     -0.174      0.862      -0.611       0.512\n",
       "Personal        0.0208      0.076      0.274      0.784      -0.128       0.170\n",
       "PhD            -8.8515      5.378     -1.646      0.100     -19.413       1.710\n",
       "Terminal       -1.5801      5.936     -0.266      0.790     -13.238      10.077\n",
       "S_F_Ratio      18.2103     15.218      1.197      0.232     -11.676      48.096\n",
       "perc_alumni    -0.1343      4.959     -0.027      0.978      -9.873       9.604\n",
       "Expend          0.0822      0.014      5.820      0.000       0.054       0.110\n",
       "Grad_Rate       9.0081      3.468      2.598      0.010       2.197      15.819\n",
       "==============================================================================\n",
       "Omnibus:                      367.855   Durbin-Watson:                   2.052\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             6382.346\n",
       "Skew:                           2.270   Prob(JB):                         0.00\n",
       "Kurtosis:                      18.035   Cond. No.                     1.87e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.87e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = list(data.columns)\n",
    "X.remove('Apps')\n",
    "\n",
    "X_train = sm.add_constant(train[X])\n",
    "y_train = train['Apps']\n",
    "X_test = sm.add_constant(test[X])\n",
    "y_test = test['Apps']\n",
    "# X_t = (auto[['cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'year', 'origin']])\n",
    "\n",
    "# Fit the linear regression model\n",
    "model = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "640045.0279060608"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(sm.add_constant(test[X]))\n",
    "\n",
    "test_MSE = mean_squared_error(test['Apps'], y_pred)\n",
    "test_MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll fit a ridge regression using Kfold cross-validation to tune $\\lambda$ over MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeCV(alphas=array([ 100.        ,  104.81131342,  109.8541142 ,  115.13953993,\n",
       "        120.67926406,  126.48552169,  132.57113656,  138.94954944,\n",
       "        145.63484775,  152.64179672,  159.98587196,  167.68329368,\n",
       "        175.75106249,  184.20699693,  193.06977289,  202.35896477,\n",
       "        212.09508879,  222.29964825,  232.99518105,  244.20530945,\n",
       "        255.95479227,  268.26957953,  281.1768698 ,  294.70517026,\n",
       "        308.88435965,  323.74575428,...\n",
       "        372.75937203,  390.69399371,  409.49150624,  429.19342601,\n",
       "        449.8432669 ,  471.48663635,  494.17133613,  517.94746792,\n",
       "        542.86754393,  568.9866029 ,  596.36233166,  625.05519253,\n",
       "        655.12855686,  686.648845  ,  719.685673  ,  754.31200634,\n",
       "        790.60432109,  828.64277285,  868.51137375,  910.29817799,\n",
       "        954.09547635, 1000.        ]),\n",
       "        cv=KFold(n_splits=10, random_state=42, shuffle=True), normalize=True,\n",
       "        scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas = np.logspace(2, 3, 50)  # 50 equally spaced lambda values from 10^2 to 10^3\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "ridge_cv = RidgeCV(alphas=alphas, cv=kf, scoring='neg_mean_squared_error', normalize=True)\n",
    "\n",
    "# Fit the RidgeCV model on the training data\n",
    "ridge_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "30e324b543df214a6e87e7c491f84215",
     "grade": false,
     "grade_id": "cell-58a9a48e40ec25b5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n",
      "13146544.500145046\n"
     ]
    }
   ],
   "source": [
    "# Get the selected lambda (alpha)\n",
    "ridge_select = ridge_cv.alpha_\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = ridge_cv.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE) on the test set\n",
    "test_MSE_ridge = mean_squared_error(y_test, predictions)\n",
    "print(ridge_select)\n",
    "print(test_MSE_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "56252675fa4e6f421978918ae5db5a4e",
     "grade": false,
     "grade_id": "cell-a93260d7bb8372f2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Comparing the ridge regression coefficients when using $\\lambda = 0$ and the value for $\\lambda$ given by `RidgeCV`, we can see how much lower the coefficients are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const            0.000000\n",
      "Private       -355.479131\n",
      "Accept           1.575937\n",
      "Enroll          -0.746077\n",
      "Top10perc       50.218691\n",
      "Top25perc      -14.946563\n",
      "F_Undergrad      0.052458\n",
      "P_Undergrad      0.014942\n",
      "Outstate        -0.101565\n",
      "Room_Board       0.181793\n",
      "Books           -0.049853\n",
      "Personal         0.020787\n",
      "PhD             -8.851477\n",
      "Terminal        -1.580112\n",
      "S_F_Ratio       18.210318\n",
      "perc_alumni     -0.134306\n",
      "Expend           0.082175\n",
      "Grad_Rate        9.008058\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ridge1 = Ridge(alpha=0, normalize=True)\n",
    "ridge1.fit(X_train, y_train)\n",
    "pred = ridge1.predict(X_test)\n",
    "print (pd.Series(ridge1.coef_, index=X_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const           0.000000\n",
      "Private       -35.623380\n",
      "Accept          0.014659\n",
      "Enroll          0.035786\n",
      "Top10perc       0.717930\n",
      "Top25perc       0.660805\n",
      "F_Undergrad     0.006368\n",
      "P_Undergrad     0.010873\n",
      "Outstate        0.000429\n",
      "Room_Board      0.005126\n",
      "Books           0.030147\n",
      "Personal        0.010215\n",
      "PhD             0.888409\n",
      "Terminal        0.947271\n",
      "S_F_Ratio       0.736176\n",
      "perc_alumni    -0.202565\n",
      "Expend          0.001861\n",
      "Grad_Rate       0.376049\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ridge1 = Ridge(alpha=ridge_select, normalize=True)\n",
    "ridge1.fit(X_train, y_train)\n",
    "pred = ridge1.predict(X_test)\n",
    "print (pd.Series(ridge1.coef_, index=X_train.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll fit a lasso model using Kfold cross-validation to tune $\\lambda$ over MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoCV(alphas=array([ 100.        ,  104.81131342,  109.8541142 ,  115.13953993,\n",
       "        120.67926406,  126.48552169,  132.57113656,  138.94954944,\n",
       "        145.63484775,  152.64179672,  159.98587196,  167.68329368,\n",
       "        175.75106249,  184.20699693,  193.06977289,  202.35896477,\n",
       "        212.09508879,  222.29964825,  232.99518105,  244.20530945,\n",
       "        255.95479227,  268.26957953,  281.1768698 ,  294.70517026,\n",
       "        308.88435965,  323.74575428,...64803062,\n",
       "        372.75937203,  390.69399371,  409.49150624,  429.19342601,\n",
       "        449.8432669 ,  471.48663635,  494.17133613,  517.94746792,\n",
       "        542.86754393,  568.9866029 ,  596.36233166,  625.05519253,\n",
       "        655.12855686,  686.648845  ,  719.685673  ,  754.31200634,\n",
       "        790.60432109,  828.64277285,  868.51137375,  910.29817799,\n",
       "        954.09547635, 1000.        ]),\n",
       "        cv=KFold(n_splits=10, random_state=42, shuffle=True), normalize=True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas = np.logspace(2, 3, 50)  # 50 equally spaced lambda values from 10^2 to 10^3\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "lasso_cv = LassoCV(alphas=alphas, cv=kf, normalize=True)\n",
    "\n",
    "# Fit the RidgeCV model on the training data\n",
    "lasso_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n",
      "6685061.618833576\n"
     ]
    }
   ],
   "source": [
    "# Get the selected lambda (alpha)\n",
    "lasso_select = lasso_cv.alpha_\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = lasso_cv.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE) on the test set\n",
    "test_MSE_lasso = mean_squared_error(y_test, predictions)\n",
    "print(lasso_select)\n",
    "print(test_MSE_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see a much lower MSE with the lasso regression than the ridge regression suggesting that is the model to use.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
